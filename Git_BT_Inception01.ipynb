{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carridl190/Pred_Models/blob/main/Git_BT_Inception01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E0-MG6TIrcI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inx7GB1sNC60"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import cv2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuGWKHyWNC87"
      },
      "source": [
        "# CNN Based Model in Keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), name = \"L1\", input_shape=(224,224,3)))\n",
        "model.add(Activation('relu', name = \"L2\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), name = \"L3\"))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), name = \"L4\"))\n",
        "model.add(Activation('relu', name = \"L5\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), name = \"L6\"))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), name = \"L7\"))\n",
        "model.add(Activation('relu', name = \"L8\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name = \"L9\"))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), name = \"L10\"))\n",
        "model.add(Activation('relu', name = \"L11\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), name = \"L12\"))\n",
        "\n",
        "model.add(Flatten(name = \"L13\"))\n",
        "model.add(Dense(64, name = \"L14\"))\n",
        "model.add(Activation('relu', name = \"L15\"))\n",
        "model.add(Dropout(0.5, name = \"L16\"))\n",
        "model.add(Dense(1,name = \"L17\"))\n",
        "model.add(Activation('softmax', name = \"L18\"))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvJ7lB_5NC_i"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZHHBnf9NDCU"
      },
      "source": [
        "#Train from scratch\n",
        "#Data Augmentation\n",
        "train_datagen = image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        ")\n",
        "\n",
        "test_datagen = image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Ad0mLDNDGm"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/YourPath_Name',\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = \"binary\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTepD_cWNDLR"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fokK2WSLNE9H"
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/YourPath_Name',\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = \"binary\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1a8VJ2dNE_5"
      },
      "source": [
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=3,\n",
        "    epochs = 15,\n",
        "    batch_size=10,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdE4hYGYhAL_"
      },
      "source": [
        "for layer in model.layers:\n",
        "    weights = layer.get_weights() # list of numpy arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8l8piMafKc5"
      },
      "source": [
        "plt.plot(hist.history['accuracy'], label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzBLSH4ak3Rv"
      },
      "source": [
        "plt.plot(hist.history['loss'], label='loss')\n",
        "plt.plot(hist.history['val_loss'], label = 'val_loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv6av2yZNFC3"
      },
      "source": [
        "model.save(\"BTSeg_DetNet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf1NWFfYNFXH"
      },
      "source": [
        "model.evaluate(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3lA-K8HNDKT"
      },
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3bPEHMWNDEx"
      },
      "source": [
        "#Test Images\n",
        "\n",
        "model = load_model(\"Your_ModelName\")\n",
        "\n",
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFfufqaNSLbn"
      },
      "source": [
        "y_actual = []\n",
        "y_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkN0b0jJSLE7"
      },
      "source": [
        "for i in os.listdir(\"YourFile_Path\"):\n",
        "    img = image.load_img(\"YourFile_Path\"+i, target_size = (224,224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "    p = model.predict(img)\n",
        "    #p = model.predict_classes(img)\n",
        "    y_test.append(p[0,0])\n",
        "    y_actual.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKpobSO5SK8U"
      },
      "source": [
        "for i in os.listdir(\"/YourFile_Path\"):\n",
        "    img = image.load_img(\"/YourFile_Path\"+i, target_size = (224,224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "    p = model.predict(img)\n",
        "    #p = model.predict_classes(img)\n",
        "    y_test.append(p[0,0])\n",
        "    y_actual.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-pmM9ImSSio"
      },
      "source": [
        "y_actual = np.array(y_actual)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "cm = confusion_matrix(y_actual, y_test)\n",
        "\n",
        "sns.heatmap(cm, cmap=\"plasma\", annot=True, xticklabels=('Meninglioma','Pituitary'), yticklabels=('Meninglioma','Pituitary'))\n",
        "plt.ylabel('True Data')\n",
        "plt.xlabel('Predicted Data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Rn9-MjelA2"
      },
      "source": [
        "#Entrenamiento y validacion se utilizan para saber cuando terminar el entrenamiento\n",
        "#Matriz de confusion es herramienta gráfica que indica precisiones\n",
        "#Kaggle concursos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F26yys8oF03F"
      },
      "source": [
        "NORMAL_TEST_PATH = \"/YourFile_Path.jpg\"\n",
        "COVID_TEST_PATH = \"/YourFile_Path.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WFq-Z3-FJ0E"
      },
      "source": [
        "#To test a single image\n",
        "\n",
        "img = image.load_img(COVID_TEST_PATH, target_size=(224,224))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "X = image.img_to_array(img)\n",
        "X = np.expand_dims(X,axis = 0)\n",
        "images = np.vstack([X])\n",
        "val = model.predict(images)\n",
        "if val == 0:\n",
        "  print(\"Meninglioma detected\")\n",
        "else:\n",
        "  print(\"Pituitary Detected\")\n",
        "\n",
        "# print(\"Predicted:\", decode_predictions(preds, top=1)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ5u64K_OdDp"
      },
      "source": [
        "MENINGLIOMA_FLDR_TEST_PATH = \"/YourFile_Path\"\n",
        "PITUITARY_FLDER_TEST_PATH = \"/YourFile_Path\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m4LIEhJFKBQ"
      },
      "source": [
        "# To test a whole folder with images\n",
        "\n",
        "for i in os.listdir(MENINGLIOMA_FLDR_TEST_PATH):\n",
        "  img = image.load_img(PITUITARY_FLDER_TEST_PATH+'//'+ i, target_size=(224,224))\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "  X = image.img_to_array(img)\n",
        "  X = np.expand_dims(X,axis = 0)\n",
        "  images = np.vstack([X])\n",
        "  val = model.predict(images)\n",
        "  if val == 0:\n",
        "    print(\"Meninglioma detected\")\n",
        "  else:\n",
        "    print(\"Pituitary Detected\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f47opqbpKiZB"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Display\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoCFOiflKiQ7"
      },
      "source": [
        "model_builder = keras.applications.xception.Xception\n",
        "img_size = (299, 299)\n",
        "preprocess_input = keras.applications.xception.preprocess_input\n",
        "decode_predictions = keras.applications.xception.decode_predictions\n",
        "\n",
        "last_conv_layer_name = \"block14_sepconv2_act\"\n",
        "classifier_layer_names = [\n",
        "    \"avg_pool\",\n",
        "    \"predictions\",\n",
        "]\n",
        "\n",
        "# The local path to our target image\n",
        "img_path = \"./Your_image_path.jpg\"\n",
        "\n",
        "display(Image(img_path, width = 224, height = 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBhN0yXNK1Qx"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrIes93pK1J8"
      },
      "source": [
        "# Prepare image\n",
        "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
        "\n",
        "# Make model\n",
        "model = model_builder(weights=\"imagenet\")\n",
        "\n",
        "# Print what the top predicted class is\n",
        "preds = model.predict(img_array)\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
        ")\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFQ0T6-KiB-"
      },
      "source": [
        "# We load the original image\n",
        "img = keras.preprocessing.image.load_img(img_path)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "# We rescale heatmap to a range 0-255\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "# We use jet colormap to colorize heatmap\n",
        "jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "# We use RGB values of the colormap\n",
        "jet_colors = jet(np.arange(256))[:, :3]\n",
        "jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "# We create an image with RGB colorized heatmap\n",
        "jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "# Superimpose the heatmap on original image\n",
        "superimposed_img = jet_heatmap * 0.4 + img\n",
        "superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "# Save the superimposed image\n",
        "save_path = \"img.jpg\"\n",
        "superimposed_img.save(save_path)\n",
        "\n",
        "# Display Grad CAM\n",
        "display(Image(save_path, width = 224, height = 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_dzVy305xtD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v77ne4V5xqH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21PhSOTddFmg"
      },
      "source": [
        "import tensorflow as tf;\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByHlppILdFbb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "import os\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le8d56F8dFH7"
      },
      "source": [
        "new_model = tf.keras.models.load_model('Your_ModelName')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBQblCTRdEzV"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXxCI-BkhLko"
      },
      "source": [
        "class GradCAM:\n",
        "\tdef __init__(self, model, classIdx, layerName=None):\n",
        "\t\t# store the model, the class index used to measure the class\n",
        "\t\t# activation map, and the layer to be used when visualizing\n",
        "\t\t# the class activation map\n",
        "\t\tself.model = model\n",
        "\t\tself.classIdx = classIdx\n",
        "\t\tself.layerName = layerName\n",
        "\t\t# if the layer name is None, attempt to automatically find\n",
        "\t\t# the target output layer\n",
        "\t\tif self.layerName is None:\n",
        "\t\t\tself.layerName = self.find_target_layer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHghXbqghLcG"
      },
      "source": [
        "\tdef find_target_layer(self):\n",
        "\t\t# attempt to find the final convolutional layer in the network\n",
        "\t\t# by looping over the layers of the network in reverse order\n",
        "\t\tfor layer in reversed(self.model.layers):\n",
        "\t\t\t# check to see if the layer has a 4D output\n",
        "\t\t\tif len(layer.output_shape) == 4:\n",
        "\t\t\t\treturn layer.name\n",
        "\t\t# otherwise, we could not find a 4D layer so the GradCAM\n",
        "\t\t# algorithm cannot be applied\n",
        "\t\traise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eiKRpRbhLTw"
      },
      "source": [
        "def compute_heatmap(self, image, eps=1e-8):\n",
        "        gradModel = Model(\n",
        "            inputs=[self.model.inputs],\n",
        "            outputs=[self.model.get_layer(self.layerName).output,\n",
        "                self.model.output])\n",
        "        # record operations for automatic differentiation\n",
        "        with tf.GradientTape() as tape:\n",
        "            inputs = tf.cast(image, tf.float32)\n",
        "            (convOutputs, predictions) = gradModel(inputs)\n",
        "            loss = predictions[:, self.classIdx]\n",
        "        # use automatic differentiation to compute the gradients\n",
        "        grads = tape.gradient(loss, convOutputs)\n",
        "        # compute the guided gradients\n",
        "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
        "        castGrads = tf.cast(grads > 0, \"float32\")\n",
        "        guidedGrads = castConvOutputs * castGrads * grads\n",
        "        convOutputs = convOutputs[0]\n",
        "        guidedGrads = guidedGrads[0]\n",
        "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
        "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
        "# resize the heatmap to oringnal X-Ray image size\n",
        "        (w, h) = (image.shape[2], image.shape[1])\n",
        "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
        "# normalize the heatmap\n",
        "        numer = heatmap - np.min(heatmap)\n",
        "        denom = (heatmap.max() - heatmap.min()) + eps\n",
        "        heatmap = numer / denom\n",
        "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
        "# return the resulting heatmap to the calling function\n",
        "        return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlYeFlddhLDM"
      },
      "source": [
        "filename = \"./Your_imagePath.jpg\"\n",
        "orignal = cv2.imread(filename)\n",
        "plt.imshow(orignal)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvnZr_GlhLBI"
      },
      "source": [
        "orig = cv2.cvtColor(orignal, cv2.COLOR_BGR2RGB)\n",
        "resized = cv2.resize(orig, (224, 224))\n",
        "dataXG = np.array(resized) / 255.0\n",
        "dataXG = np.expand_dims(dataXG, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tr5jMBshK3_"
      },
      "source": [
        "preds = new_model.predict(dataXG)\n",
        "i = np.argmax(preds[0])\n",
        "print(i, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_MqPC4OdEqk"
      },
      "source": [
        "# Old fashioned way to overlay a transparent heatmap onto original image, the same as above\n",
        "heatmapY = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n",
        "heatmapY = cv2.applyColorMap(heatmapY, cv2.COLORMAP_VIRIDIS)  # COLORMAP_JET, COLORMAP_VIRIDIS, COLORMAP_HOT\n",
        "imageY = cv2.addWeighted(heatmapY, 0.5, orignal, 1.0, 0)\n",
        "print(heatmapY.shape, orig.shape)\n",
        "# draw the orignal x-ray, the heatmap, and the overlay together\n",
        "output = np.hstack([orig, heatmapY, imageY])\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.imshow(np.random.rand(1, 99), interpolation='nearest')\n",
        "plt.imshow(output)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}